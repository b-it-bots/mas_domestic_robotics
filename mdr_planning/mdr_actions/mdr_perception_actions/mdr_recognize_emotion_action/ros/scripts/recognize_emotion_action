#!/usr/bin/env python
import rospy
import smach

from smach_ros import ActionServerWrapper, IntrospectionServer

from mdr_recognize_emotion_action.msg import RecognizeEmotionAction
from mdr_recognize_emotion_action.action_states import (SetupRecognizeEmotion, RecognizeEmotion,
                                                     SetActionLibResult)


class RecognizeEmotionSkill(smach.StateMachine):
    def __init__(self, timeout=10):
        smach.StateMachine.__init__(self,
                                    outcomes=['OVERALL_SUCCESS',
                                              'OVERALL_FAILED', 'PREEMPTED'],
                                    input_keys=['recognize_emotion_goal'],
                                    output_keys=['recognize_emotion_feedback',
                                                 'recognize_emotion_result'])

        emotion_model_path = rospy.get_param('~emotion_model_path', '')
        image_topic = rospy.get_param('~image_topic', '/cam3d/rgb/image_raw')
        labels = {0: 'angry', 1: 'disgusted', 2: 'sad', 3: 'happy',
                  4: 'sad', 5: 'surprised', 6: 'neutral'}
        image_size = (48, 48, 1)

        with self:
            smach.StateMachine.add('SETUP_RECOGNIZE_EMOTION',
                                   SetupRecognizeEmotion(),
                                   transitions={'succeeded': 'RECOGNIZE_EMOTION',
                                                'failed': 'SETUP_RECOGNIZE_EMOTION'})

            smach.StateMachine.add('RECOGNIZE_EMOTION',
                                   RecognizeEmotion(emotion_model_path=emotion_model_path,
                                                 image_topic=image_topic,
                                                 labels=labels, image_size=image_size),
                                   transitions={'succeeded': 'SET_ACTION_LIB_SUCCESS',
                                                'failed': 'SET_ACTION_LIB_FAILED'})

            smach.StateMachine.add('SET_ACTION_LIB_FAILED',
                                   SetActionLibResult(False),
                                   transitions={'succeeded': 'OVERALL_FAILED'})

            smach.StateMachine.add('SET_ACTION_LIB_SUCCESS',
                                   SetActionLibResult(True),
                                   transitions={'succeeded': 'OVERALL_SUCCESS'})


if __name__ == '__main__':
    rospy.init_node('recognize_emotion_server')

    # construct state machine
    sm = RecognizeEmotionSkill()

    # smach viewer
    sis = IntrospectionServer('recognize_emotion_smach_viewer', sm,
                              '/recognize_emotion_SMACH_VIEWER')
    sis.start()

    asw = ActionServerWrapper(
        server_name='recognize_emotion_server',
        action_spec=RecognizeEmotionAction,
        wrapped_container=sm,
        succeeded_outcomes=['OVERALL_SUCCESS'],
        aborted_outcomes=['OVERALL_FAILED'],
        preempted_outcomes=['PREEMPTED'],
        goal_key='recognize_emotion_goal',
        feedback_key='recognize_emotion_feedback',
        result_key='recognize_emotion_result')

    # Run the server in a background thread
    asw.run_server()
    rospy.spin()
