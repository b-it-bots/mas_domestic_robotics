#!/usr/bin/env python2
from dynamic_reconfigure.parameter_generator_catkin import ParameterGenerator, double_t, int_t, bool_t, str_t


PACKAGE='mdr_cloud_object_detection'
NODE_NAME = PACKAGE

gen = ParameterGenerator()

# cloud filter group
cloud_filter_params = gen.add_group("Cloud Filter")

# pass-through filter parameters
cloud_filter_params.add("passthrough_limit_min_x", double_t, 0,
                        "Minimum field value of a point along x-axis for it to be considered", 0.0, 0.0, 10.0)

cloud_filter_params.add("passthrough_limit_max_x", double_t, 0,
                        "Maximum field value of a point along x-axis for it to be considered", 3.0, 0.0, 10.0)

cloud_filter_params.add("passthrough_limit_min_y", double_t, 0,
                        "Minimum field value of a point along y-axis for it to be considered", -1.5, -3.0, 3.0)

cloud_filter_params.add("passthrough_limit_max_y", double_t, 0,
                        "Maximum field value of a point along y-axis for it to be considered", 1.5, -3.0, 3.0)

cloud_filter_params.add("passthrough_limit_min_z", double_t, 0,
                        "Minimum field value of a point along z-axis for it to be considered", 0.025, 0.0, 5.0)

cloud_filter_params.add("passthrough_limit_max_z", double_t, 0,
                        "Maximum field value of a point along z-axis for it to be considered", 0.2, 0.0, 5.0)

# voxel-grid filter parameters; note that we limit the cloud along the z-axis using the voxel filter to avoid adding
# a third pass-through filter
cloud_filter_params.add("voxel_limit_min_z", double_t, 0,
                        "Minimum field value of a point along z-axis for it to be considered", 0.0, -10.0, 10.0)
cloud_filter_params.add("voxel_limit_max_z", double_t, 0,
                        "Maximum field value of a point along z-axis for it to be considered", 1.0, -10.0, 10.0)
cloud_filter_params.add("voxel_leaf_size", double_t, 0, "Size of a leaf (on x,y,z) used for downsampling.",
                        0.01, 0, 1.0)

# Euclidean Clustering
euclidean_clustering_params = gen.add_group("Euclidean Clustering")

# clustering parameters
euclidean_clustering_params.add("cluster_tolerance", double_t, 0, 
                        "Spatial cluster tolerance as a measure in the L2 Euclidean space",
                        0.03, 0.0, 0.1)
euclidean_clustering_params.add("min_cluster_size", int_t, 0, 
                        "The minimum number of points that a cluster needs to contain in order to be considered valid",
                        5, 0, 1000)
euclidean_clustering_params.add("max_cluster_size", int_t, 0, 
                        "The maximum number of points that a cluster needs to contain in order to be considered valid",
                        100000, 0, 1000000)

# Object Filtering
object_filter_params = gen.add_group("Object Filter")
object_filter_params.add("max_bbox_edge_length", double_t, 0, 
                        "Maximum allowed length (in meters) of any of the bounding box edges for an object.\
                         Any clusters with a length greater that this value will not be considered as objects.",
                        .15, 0, 1)
object_filter_params.add("min_dist_from_occupied_cell", double_t, 0, 
                        "Minimum required distance (in meters) of a valid object from an occupied cell in the occupancy grid map.\
                         Any clusters with a distance less that this value will not be considered as objects.",
                        .1, 0, 1)

# Object Cache
object_cache_params = gen.add_group("Object Cache")
object_cache_params.add("object_cache_time", double_t, 0, 
                        "Maximum time (in seconds) for which an object can say in cache after it is no longer visible/detected.",
                        5, 0, 100)
object_cache_params.add("similarity_threshold", double_t, 0, 
                        "threshold for identifying outliers and not considering those for the similarity \
                         a good value for threshold is 5 * <cloud_resolution>, e.g. 10cm for a cloud with 2cm resolution",
                        2.0, 0.0, 100.0)
object_cache_params.add("position_history_cache_size", int_t, 0, 
                        "Maximum number of past object positions to remember",
                        10, 0, 1000)
object_cache_params.add("uniqueness_threshold", double_t, 0, 
                        "Threshold to determine a new cluster is the same as a cached cluster. \
                         If the similarity measure is below this value, the new cluster is considered as a replica of a cached cluster.",
                        0.005, 0.0, 10.0)

exit (gen.generate (PACKAGE, NODE_NAME, "ObjectDetection"))
